{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task1_Location_Fatalities_Final.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qaG4H8Bu8OK5"},"outputs":[],"source":["# Load a spacy model and chekc if it has ner\n","import spacy\n","nlp=spacy.load('en_core_web_sm')\n","from spacy.tokens import Span\n","import difflib"]},{"cell_type":"code","source":["# Getting Locations\n","import numpy as np\n","import pandas as pd\n","data = pd.read_csv('task_1_information_extraction_valid.tsv', sep='\\t')\n","print(len(data))\n","data = data[data['NOTES'].notna()]\n","data = data.reset_index(drop=True)\n","data.head()"],"metadata":{"id":"Xnmji-2H96iY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"DK_RQApT60PQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","import spacy\n","  \n","# essential entity models downloads\n","nltk.downloader.download('maxent_ne_chunker')\n","nltk.downloader.download('words')\n","nltk.downloader.download('treebank')\n","nltk.downloader.download('maxent_treebank_pos_tagger')\n","nltk.downloader.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"id":"N1jAIThK7hqH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install locationtagger\n","import locationtagger"],"metadata":{"id":"txVgOwx17uEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Get Location from text, a text can also contain multiple locations\n","def getlocation():\n","    countries = []\n","    regions = []\n","    cities = []\n","    for i in range(len(data)):\n","        line = data['NOTES'][i]\n","\n","        if (i % 1000) == 0 and (i != 0):\n","            print(\"Finished Sentense :\", i)\n","\n","        place_entity = locationtagger.find_locations(text = line)\n","\n","        # if param == 'countries':\n","        countries.append(place_entity.countries)\n","        \n","        # if param == 'regions':\n","        regions.append(place_entity.regions)\n","        \n","        # if param == 'cities':\n","        cities.append(place_entity.cities)\n","\n","    return countries, regions, cities\n","\n","countries, regions, cities = getlocation()"],"metadata":{"id":"iCAEoOua7ntu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving Arrays to files\n","# with open(\"countries.txt\", \"w\") as f:\n","#     for s in countries:\n","#         f.write(str(s) +\"\\n\")\n","\n","# with open(\"regions.txt\", \"w\") as f:\n","#     for s in regions:\n","#         f.write(str(s) +\"\\n\")\n","\n","# with open(\"cities.txt\", \"w\") as f:\n","#     for s in cities:\n","#         f.write(str(s) +\"\\n\")"],"metadata":{"id":"LZebtW0mLv-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading arrays from files\n","# countries = []\n","# with open(\"countries.txt\", \"r\") as f:\n","#   for line in f:\n","#     countries.append(line.strip())\n","\n","# regions = []\n","# with open(\"regions.txt\", \"r\") as f:\n","#   for line in f:\n","#     regions.append(line.strip())\n","\n","# cities = []\n","# with open(\"cities.txt\", \"r\") as f:\n","#   for line in f:\n","#     cities.append(line.strip())"],"metadata":{"id":"vbZD4_m5Mv4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(countries)"],"metadata":{"id":"KxBgKwmLOGyC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cities[1].strip()"],"metadata":{"id":"m70MlF_QOJd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getcounts(Locations):\n","    count = 0\n","    for i in range(len(Locations)):\n","        if not Locations[i]:\n","            count = count + 1\n","\n","    print(len(Locations))\n","    print(\"Total Empty Locations: \", count)\n","\n","getcounts(countries)\n","getcounts(regions)\n","getcounts(cities)"],"metadata":{"id":"rYrHA2vMMdVX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using Spacy on Empty Locations\n","def spacy(Locations):\n","    for i in range(len(Locations)):\n","        if not Locations[i]:\n","            doc = nlp(data['NOTES'][i])\n","            loc = []\n","            for ent in doc.ents:  \n","                if ent.label_ in 'LOC':\n","                    Locations[i] = ent.text\n","                    # loc.append(ent.text)\n","                    continue\n","                elif ent.label_ in 'GPE':\n","                    # loc.append(ent.text)\n","                    Locations[i] = ent.text\n","                    continue\n","spacy(countries)\n","spacy(regions)\n","spacy(cities)"],"metadata":{"id":"JEhQjufJJKCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Actual_Locations = data['LOCATION']"],"metadata":{"id":"rxyaD5CVFpmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Accuracy\n","def getAccuracy(Locations):\n","    correct = 0\n","    for i in range(len(Locations)):\n","\n","        if not Locations[i]:\n","            continue\n","\n","        if difflib.SequenceMatcher(None,Locations[i],Actual_Locations[i]).ratio() >= 0.3:\n","            correct += 1\n","\n","    # print(correct)\n","    print(\"Accuracy :\", correct/len(Locations))\n","\n","getAccuracy(countries)\n","# getAccuracy(regions)\n","# getAccuracy(cities)"],"metadata":{"id":"tvHOiJktaYPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting Fatalities\n","Numbers = []\n","import numpy as np\n","for i in range(len(data)):\n","    line = data['NOTES'][i]\n","    doc = nlp(line)\n","\n","    if (i % 1000) == 0 and (i != 0):\n","        print(\"Finished Sentense :\", i)\n","\n","    num = []\n","    for ent in doc.ents:  \n","        if ent.label_ in ['CARDINAL']:\n","            num.append(ent.text)\n","        else:\n","            num.append(0)\n","\n","    Numbers.append(num)"],"metadata":{"id":"UvwEhkvhwAdg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(Numbers)"],"metadata":{"id":"xxf0m340rVGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Removing sentences which return 0 cardinals \n","for i in range(len(Numbers)):\n","    if Numbers[i] != []:\n","        F1.append(Numbers[i][0])\n","    else:\n","        F1.append(0)"],"metadata":{"id":"X64rWpTTiahZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Removing dates, converting string to lower from sentences \n","from re import search\n","F2 = F1.copy()\n","for i in range(len(F2)):\n","    if type(F2[i]) == str:\n","        F2[i] = F2[i].lower()\n","        if search('/', F2[i]) or search(':', F2[i]):\n","            F2[i] = 0\n","    else:\n","        F2[i] = F2[i]"],"metadata":{"id":"-1wY-GlnIEZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["F2"],"metadata":{"id":"kk2c3Btp6rIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting bigger strings\n","F3 = F2.copy()\n","for i in range(len(F3)):\n","    if type(F3[i]) == str:\n","        x = F3[i].split()\n","        if len(x) > 1:\n","            for j in x:\n","                doc = nlp(j)\n","                for ent in doc.ents:  \n","                    if ent.label_ in ['CARDINAL']:\n","                        F3[i] = ent.text\n","                    else:\n","                        F3[i] = 0\n","    else:\n","        F3[i] = F2[i]"],"metadata":{"id":"hwAPp1jy4igM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["F3"],"metadata":{"id":"839WQPcy6mpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert strings to numbers\n","# !pip install word2number\n","# !pip install pattern\n","from word2number import w2n\n","from pattern.text.en import singularize\n","F4 = F3.copy()\n","for i in range(len(F4)):\n","    if type(F4[i]) == str:\n","        try:\n","            F4[i] = w2n.word_to_num(F4[i])\n","        except Exception:\n","            pass\n","    else:\n","        F4[i] = F3[i]"],"metadata":{"id":"ZYcTCiyI23e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(F4)"],"metadata":{"id":"t8iZ8Ur9DA4z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving Predicted Fatalities\n","# with open(\"fatalities.txt\", \"w\") as f:\n","#     for s in F4:\n","#         f.write(str(s) +\"\\n\")"],"metadata":{"id":"ST3C1focVlZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# F4 = []\n","# with open(\"fatalities.txt\", \"r\") as f:\n","#   for line in f:\n","#     F4.append(line.strip())"],"metadata":{"id":"fQLJAPPUVtUc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Actual_Fatalities = data['FATALITIES']"],"metadata":{"id":"83jDdnPbm95z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating Accuracy\n","correct = 0\n","result1 = []\n","result2 = []\n","for i in range(len(Actual_Fatalities)):\n","    try:\n","        if Actual_Fatalities[i] == int(F4[i]):\n","            correct += 1\n","            result1.append([i, Actual_Fatalities[i], F4[i]])\n","    except Exception:\n","            pass\n","\n","print(\"Accuracy\")\n","print(correct/len(Actual_Fatalities))"],"metadata":{"id":"U2e3hSPTPG1I"},"execution_count":null,"outputs":[]}]}